{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_mental_illness = [\n",
    "    'offmychest',\n",
    "    'add',\n",
    "    'cripplingalcoholism',\n",
    "    'disorder',\n",
    "    'Health',\n",
    "    'HelathProject',\n",
    "    'leaves',\n",
    "    'MenGetRapedToo',\n",
    "    'rapecounseling',\n",
    "    'CupsofTea',\n",
    "    'addiction',\n",
    "    'ADHD',\n",
    "    'Advice',\n",
    "    'affirmations',\n",
    "    'afterthesilence',\n",
    "    'Agoraphobia',\n",
    "    'AlAnon',\n",
    "    'alcoholicsanonymous',\n",
    "    'alcoholism',\n",
    "    'Anger',\n",
    "    'Antipsychiatry',\n",
    "    'Anxiety',\n",
    "    'Anxietyhelp',\n",
    "    'anxietysuccess',\n",
    "    'anxietysupporters'\n",
    "]\n",
    "\n",
    "post_details = ['title', 'selftext', 'is_self', 'subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "r = praw.Reddit(client_id='ycBzsDBVyAQ-tQ',\n",
    "                client_secret='uwqEKSfwzxUosVC_JTpYk18zdlU',\n",
    "                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.108 Safari/537.36')\n",
    "page = r.subreddit('mentalhealth')\n",
    "top_posts = page.hot(limit=1)\n",
    "for post in top_posts:\n",
    "    print('title:', post.title, '\\n',\n",
    "          'selftext:', post.selftext, '\\n', \n",
    "          'is_self', post.is_self, '\\n',\n",
    "          'likes', post.likes, '\\n',\n",
    "          'subreddit', str(post.subreddit), '\\n',\n",
    "          'name', post.fullname, '\\n',\n",
    "          dir(post))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subreddits_posts():\n",
    "    import praw\n",
    "    r = praw.Reddit(client_id='ycBzsDBVyAQ-tQ',\n",
    "                client_secret='uwqEKSfwzxUosVC_JTpYk18zdlU',\n",
    "                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.108 Safari/537.36')\n",
    "    subreddits_dict = {'title':[], 'selftext':[],'subreddit':[],'is_self':[]}\n",
    "    for topic in subreddits_mental_illness:\n",
    "        try:\n",
    "            page = r.subreddit(topic)\n",
    "            top_posts = page.hot(limit=None)\n",
    "            for post in top_posts:\n",
    "                try:\n",
    "                    subreddits_dict['title'].append(post.title)  \n",
    "                except:\n",
    "                    subreddits_dict['title'].append('uknown') \n",
    "                    continue\n",
    "                try:\n",
    "                    subreddits_dict['selftext'].append(post.selftext)\n",
    "                except:\n",
    "                    subreddits_dict['selftext'].append('uknown') \n",
    "                    continue    \n",
    "                try:\n",
    "                    subreddits_dict['subreddit'].append(str(post.subreddit))\n",
    "                except:\n",
    "                    subreddits_dict['subreddit'].append('uknown') \n",
    "                    continue    \n",
    "                try:\n",
    "                    subreddits_dict['is_self'].append(post.is_self)\n",
    "                except:\n",
    "                    subreddits_dict['is_self'].append('uknown') \n",
    "                    continue    \n",
    "        except:\n",
    "            continue\n",
    "    return subreddits_dict\n",
    "\n",
    "my_dict = get_subreddits_posts()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_self</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please be wary of people asking for donations....</td>\n",
       "      <td>A day or two ago a post popped up by a girl cl...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm finally okay with what I lost.</td>\n",
       "      <td>I had my daughter at sixteen. I'm now in colle...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...</td>\n",
       "      <td>That is all. Thank you for your time.</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I told my boss to fuck off and quit my job all...</td>\n",
       "      <td>I’ve been checking my hours religiously. I not...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FUCK YEA</td>\n",
       "      <td>ITS CURRENTLY 5:31 AM AND I JUST FINISHED MY 1...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Please be wary of people asking for donations....   \n",
       "1                 I'm finally okay with what I lost.   \n",
       "2  VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...   \n",
       "3  I told my boss to fuck off and quit my job all...   \n",
       "4                                           FUCK YEA   \n",
       "\n",
       "                                            selftext   subreddit  is_self  \n",
       "0  A day or two ago a post popped up by a girl cl...  offmychest     True  \n",
       "1  I had my daughter at sixteen. I'm now in colle...  offmychest     True  \n",
       "2              That is all. Thank you for your time.  offmychest     True  \n",
       "3  I’ve been checking my hours religiously. I not...  offmychest     True  \n",
       "4  ITS CURRENTLY 5:31 AM AND I JUST FINISHED MY 1...  offmychest     True  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(my_dict)\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv('subreddits_mental.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_self</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please be wary of people asking for donations....</td>\n",
       "      <td>A day or two ago a post popped up by a girl cl...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>Please be wary of people asking for donations....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm finally okay with what I lost.</td>\n",
       "      <td>I had my daughter at sixteen. I'm now in colle...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>I'm finally okay with what I lost. I had my da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...</td>\n",
       "      <td>That is all. Thank you for your time.</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I told my boss to fuck off and quit my job all...</td>\n",
       "      <td>I’ve been checking my hours religiously. I not...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>I told my boss to fuck off and quit my job all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FUCK YEA</td>\n",
       "      <td>ITS CURRENTLY 5:31 AM AND I JUST FINISHED MY 1...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>FUCK YEA ITS CURRENTLY 5:31 AM AND I JUST FINI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Please be wary of people asking for donations....   \n",
       "1                 I'm finally okay with what I lost.   \n",
       "2  VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...   \n",
       "3  I told my boss to fuck off and quit my job all...   \n",
       "4                                           FUCK YEA   \n",
       "\n",
       "                                            selftext   subreddit  is_self  \\\n",
       "0  A day or two ago a post popped up by a girl cl...  offmychest     True   \n",
       "1  I had my daughter at sixteen. I'm now in colle...  offmychest     True   \n",
       "2              That is all. Thank you for your time.  offmychest     True   \n",
       "3  I’ve been checking my hours religiously. I not...  offmychest     True   \n",
       "4  ITS CURRENTLY 5:31 AM AND I JUST FINISHED MY 1...  offmychest     True   \n",
       "\n",
       "                                           full_text  \n",
       "0  Please be wary of people asking for donations....  \n",
       "1  I'm finally okay with what I lost. I had my da...  \n",
       "2  VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...  \n",
       "3  I told my boss to fuck off and quit my job all...  \n",
       "4  FUCK YEA ITS CURRENTLY 5:31 AM AND I JUST FINI...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['full_text'] = raw_df['title'] + ' ' + raw_df['selftext'] \n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "\n",
    "raw_df['full_text'] = raw_df['full_text'].str.lower()  \n",
    "raw_df['full_text'] = raw_df['full_text'].str.replace('\\r','')\n",
    "raw_df['full_text'] = raw_df['full_text'].str.replace('\\n','')\n",
    "raw_df['full_text'] = raw_df['full_text'].str.replace('/',' ')\n",
    "raw_df['full_text'] = raw_df['full_text'].str.replace('  ',' ')\n",
    "raw_df['full_text'] = raw_df['full_text'].str.replace('www','')\n",
    "raw_df['full_text'] = raw_df['full_text'].str.replace('com',' ')\n",
    "raw_df['full_text'] = raw_df['full_text'].str.translate(table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_self</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please be wary of people asking for donations....</td>\n",
       "      <td>A day or two ago a post popped up by a girl cl...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>please be wary of people asking for donations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm finally okay with what I lost.</td>\n",
       "      <td>I had my daughter at sixteen. I'm now in colle...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>i m finally okay with what i lost  i had my da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...</td>\n",
       "      <td>That is all. Thank you for your time.</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>vaccines are good  they save lives  please get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I told my boss to fuck off and quit my job all...</td>\n",
       "      <td>I’ve been checking my hours religiously. I not...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>i told my boss to fuck off and quit my job all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FUCK YEA</td>\n",
       "      <td>ITS CURRENTLY 5:31 AM AND I JUST FINISHED MY 1...</td>\n",
       "      <td>offmychest</td>\n",
       "      <td>True</td>\n",
       "      <td>fuck yea its currently 5 31 am and i just fini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Please be wary of people asking for donations....   \n",
       "1                 I'm finally okay with what I lost.   \n",
       "2  VACCINES ARE GOOD! THEY SAVE LIVES! PLEASE GET...   \n",
       "3  I told my boss to fuck off and quit my job all...   \n",
       "4                                           FUCK YEA   \n",
       "\n",
       "                                            selftext   subreddit  is_self  \\\n",
       "0  A day or two ago a post popped up by a girl cl...  offmychest     True   \n",
       "1  I had my daughter at sixteen. I'm now in colle...  offmychest     True   \n",
       "2              That is all. Thank you for your time.  offmychest     True   \n",
       "3  I’ve been checking my hours religiously. I not...  offmychest     True   \n",
       "4  ITS CURRENTLY 5:31 AM AND I JUST FINISHED MY 1...  offmychest     True   \n",
       "\n",
       "                                           full_text  \n",
       "0  please be wary of people asking for donations ...  \n",
       "1  i m finally okay with what i lost  i had my da...  \n",
       "2  vaccines are good  they save lives  please get...  \n",
       "3  i told my boss to fuck off and quit my job all...  \n",
       "4  fuck yea its currently 5 31 am and i just fini...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(raw_df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spAcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\"]\n",
    "\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "def cleanText(text):\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenizeText(sample):\n",
    "    tokens = parser(sample)\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zarrina/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/zarrina/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/zarrina/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/zarrina/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5511557408109132\n"
     ]
    }
   ],
   "source": [
    "def printNMostInformative(vectorizer, clf, N):\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    topClass1 = coefs_with_fns[:N]\n",
    "    topClass2 = coefs_with_fns[:-(N + 1):-1]\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        print(feat)\n",
    "        \n",
    "vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))\n",
    "svm = LinearSVC()\n",
    "clf = CalibratedClassifierCV(svm) \n",
    "\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), \n",
    "                 ('vectorizer', vectorizer), \n",
    "                 ('clf', clf)])\n",
    "# data\n",
    "train_list = train['full_text'].tolist()\n",
    "labels_train_list = train['subreddit'].tolist()\n",
    "test_list = test['full_text'].tolist()\n",
    "labels_test_list = test['subreddit'].tolist()\n",
    "# train\n",
    "pipe.fit(train_list, labels_train_list)\n",
    "# test\n",
    "preds = pipe.predict(test_list)\n",
    "print(\"accuracy:\", accuracy_score(labels_test_list, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I told my boss to fuck off and quit my job all I've been checking my hours religiously\"]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_title = \"I told my boss to fuck off and quit my job all\"\n",
    "input_text = \"I've been checking my hours religiously\"\n",
    "all_input = [input_title + ' ' + input_text]\n",
    "\n",
    "all_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcoholicsanonymous'], dtype='<U19')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(all_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alcoholicsanonymous' 0.08697228446674221]\n",
      " ['Advice' 0.08165493496365757]\n",
      " ['Antipsychiatry' 0.07491949494032375]\n",
      " ['alcoholism' 0.07038268992277391]\n",
      " ['Anxiety' 0.06636426419905089]]\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(pipe.predict_proba(all_input), columns=pipe.classes_).T.nlargest(5, [0]).reset_index().values\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save pickle model\n",
    "pickle.dump(pipe, open(\"pipe.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib\n",
      "Successfully installed joblib-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.joblib']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(pipe, 'pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import gensim.models.doc2vec as doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(raw_df.full_text, raw_df.subreddit, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15993/15993 [00:00<00:00, 234832.74it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 585714.19it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 796233.70it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 759290.33it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1593413.08it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 2045668.14it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 717727.22it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 2032158.01it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1539898.16it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1103063.60it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1827132.18it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1681527.72it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 2087298.25it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1718401.06it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1735338.35it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1897366.74it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1398247.05it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1698688.34it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1004274.39it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1697570.64it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1676945.67it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1810219.77it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1887914.89it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1567790.96it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1640968.34it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1656243.15it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1887702.37it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 141821.03it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 1803018.60it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 969567.16it/s]\n",
      "100%|██████████| 15993/15993 [00:00<00:00, 941651.75it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = raw_df.subreddit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zarrina/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/zarrina/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5587744893705711\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "         offmychest       0.54      0.51      0.53       101\n",
      "                ADD       0.71      0.64      0.67       288\n",
      "cripplingalcoholism       0.55      0.54      0.54       279\n",
      "           Disorder       0.63      0.69      0.66       320\n",
      "             Health       0.61      0.67      0.64       305\n",
      "             leaves       0.77      0.83      0.80       309\n",
      "     MenGetRapedToo       0.69      0.78      0.73       297\n",
      "     rapecounseling       0.43      0.36      0.39       289\n",
      "          addiction       0.39      0.39      0.39       304\n",
      "               ADHD       0.05      0.17      0.07        23\n",
      "             Advice       0.09      0.14      0.11        22\n",
      "       affirmations       0.34      0.39      0.36        69\n",
      "    afterthesilence       0.55      0.50      0.52       296\n",
      "        Agoraphobia       0.54      0.47      0.50        87\n",
      "             AlAnon       0.16      0.11      0.13        71\n",
      "alcoholicsanonymous       0.55      0.53      0.54       288\n",
      "         alcoholism       0.47      0.35      0.40       308\n",
      "              Anger       0.21      0.13      0.16        63\n",
      "     Antipsychiatry       0.01      0.07      0.02        15\n",
      "            Anxiety       0.59      0.66      0.62       226\n",
      "        Anxietyhelp       0.76      0.76      0.76       295\n",
      "     anxietysuccess       0.49      0.48      0.48       275\n",
      "  anxietysupporters       0.63      0.57      0.60       268\n",
      "\n",
      "          micro avg       0.56      0.56      0.56      4798\n",
      "          macro avg       0.47      0.47      0.46      4798\n",
      "       weighted avg       0.57      0.56      0.56      4798\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6128644418122237"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=subreddits))\n",
    "\n",
    "logreg.predict_proba([test_vectors_dbow[0]]).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anxietysuccess']\n"
     ]
    }
   ],
   "source": [
    "all_input = \"One more anxiety post absolutely something nothing\"\n",
    "user_input = model_dbow.infer_vector(all_input, steps=30)\n",
    "user_input = user_input.reshape(1, -1)\n",
    "prediction = logreg.predict(user_input)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['anxietysuccess' 0.13278685398343357]\n",
      " ['Advice' 0.13198302166693113]\n",
      " ['alcoholicsanonymous' 0.11501243638252179]\n",
      " ['Anxietyhelp' 0.10803075050601131]\n",
      " ['afterthesilence' 0.08485943674430753]]\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(logreg.predict_proba(user_input), columns=logreg.classes_).T.nlargest(5, [0]).reset_index().values\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save doc2vec model\n",
    "model_dbow.save(\"doc2vec_model.pkl\")\n",
    "\n",
    "# save pickle model\n",
    "pickle.dump(logreg, open(\"model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "url = \"https://nlpsgf-env.a3pandx5ib.us-east-2.elasticbeanstalk.com/\"\n",
    "data = {'text': 'Tell me something new depression struggle'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'support_groups': [['anxietysuccess', 0.28438004007314927],\n",
       "  ['Anxietyhelp', 0.13298563554083798],\n",
       "  ['alcoholicsanonymous', 0.12444254715448964],\n",
       "  ['addiction', 0.09626223218582351],\n",
       "  ['ADD', 0.06677769775981376]]}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
